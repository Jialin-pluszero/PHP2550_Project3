---
title: "PHP2550_Project_3"
author: "Jialin Liu"
date: "2023-12-02"
output: pdf_document
---

```{r setup, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
library(riskCommunicator)
library(tidyverse)
library(dplyr)
library(tableone)
library(mice)
library(data.table)
library(fitdistrplus)
library(logspline)
library(kableExtra)
library(MASS)
```


# Introduction

Users of prediction models want to apply the models in a specific target population. Prediction models are often developed from samples in source populations, however, models cannot be directly applied to the target population since datasets are typically not random sample from the target population, even distributions of observed variables are totally different between source and target populations. Consequently, models built using the data from source population are not applicable to the target population so that model performance evaluation in the source population cannot perfectly reflect performance in the target population unless using tailored prediction models as an attractive alternative to evaluate performance in the target population to achieve transportability tasks. In many cases, both covariates and outcome are available in source populations, whereas only covariates are available in target populations without prior information about outcomes. Under the lack of outcomes in target populations, we tailor prediction models given outcomes information from the source population and assess performance of models for datasets with covariates only[1]. 

This project aimed to see if the prediction model can be generalized to the other target population by looking at the Brier scores from the transportability analysis, conducted a simulation study when individual level datasets are not available for transportability, and evaluated performance of Brier risk scores.  

## The Framingham Heart Study

It is widely accepted that age, sex, high blood pressure, smoking, dyslipidemia, and diabetes are the major risk factors for developing cardiovascular disease (CVD). The Framingham Heart Study was a landmark long term prospective study of cardiovascular disease among a population of free living subjects in the community of Framingham, Massachusetts, and identified effects of risk factors. Participants have been examined biennially since the inception of the study and all subjects are continuously followed through regular surveillance for cardiovascular outcomes. The Framingham data has been used to create models for predicting cardiovascular risk given risk factors and markers of disease, such as blood pressure, blood chemistry, lung function, smoking history, health behaviors, diagnoses of diabetes, and medication use[2]. From published scholar's work, the sex-specific multivariable risk factor algorithm was created to assess and predict CVD risk[3]. The study sample consisted of attendees of the baseline examinations free of prevalent CVD who were 30 to 74 years of age with non-missing data on covariates. Under this work's reference, we conducted variable selection including and applied models. After exclusions, 2438 participants (mean age, 59 years; 1380 women) remained eligible.

In Table 1, the risk factor characteristics of men and women in our sample at the baseline examinations are significantly different at the type-I error of 0.05. In our middle-aged sample, mean levels of systolic blood pressure and the prevalences of diabetes were similar in men and women. The prevalences of cigarette smoking and use of Anti-hypertensive medication were substantially higher in women. Then we created two new variables `SYSBP_UT` and `SYSBP_T` to get systolic blood pressure based on whether participants took medication or not. As we're not interested in measurement of hazard rates, we would like to remove censored data by examining risk within 15 years. Aiming to mimic models presented in the published works, we splitted the sample data by sex and fitted the sex-specific model with respect to log transforms for all continuous variables and selected categorical variables `CURSMOKE` and `DIABETES` to predict the probability of cardiovascular disease taking place. 

```{r}
data("framingham")

# The Framingham data has been used to create models for cardiovascular risk.
# The variable selection and model below are designed to mimic the models used
# in the paper General Cardiovascular Risk Profile for Use in Primary Care 
# This paper is available (cvd_risk_profile.pdf) on Canvas.

framingham_df <- framingham %>% dplyr::select(c(CVD, TIMECVD, SEX, TOTCHOL, AGE,
                                      SYSBP, CURSMOKE, DIABETES, BPMEDS,
                                      HDLC, BMI))
framingham_df <- na.omit(framingham_df)
framingham_df <- framingham_df %>% filter(AGE >= 30 & AGE <= 74)

# factorize all categorical variables
framingham_df$SEX <- as.factor(framingham_df$SEX)
framingham_df$CURSMOKE <- as.factor(framingham_df$CURSMOKE)
framingham_df$BPMEDS <- as.factor(framingham_df$BPMEDS)
framingham_df$DIABETES <- as.factor(framingham_df$DIABETES)

#kable
kableone(CreateTableOne(data=framingham_df, strata = c("SEX"), test = T), 
         caption = "Characteristics of Risk Factors Stratified by SEX in the Framingham Data",
         align = "c", booktabs = T,
         col.names = c("Men(1)", "Women(2)", "P-values", "")) %>%  
  kable_styling(full_width=T,latex_options = c('HOLD_position')) 

# Get blood pressure based on whether or not on BPMEDS
framingham_df$SYSBP_UT <- ifelse(framingham_df$BPMEDS == 0, 
                                 framingham_df$SYSBP, 0)
framingham_df$SYSBP_T <- ifelse(framingham_df$BPMEDS == 1, 
                                framingham_df$SYSBP, 0)

# Looking at risk within 15 years - remove censored data
# dim(framingham_df)
framingham_df <- framingham_df %>%
  filter(!(CVD == 0 & TIMECVD <= 365*15)) %>%
 dplyr:: select(-c(TIMECVD))
# dim(framingham_df)

# Filter to each sex
framingham_df_men <- framingham_df %>% filter(SEX == 1)
framingham_df_women <- framingham_df %>% filter(SEX == 2)

# Fit models with log transforms for all continuous variables
mod_men <- glm(CVD~log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, 
      data= framingham_df_men, family= "binomial")


mod_women <- glm(CVD~log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women, family= "binomial")
```

## The National Health and Nutrition Examination Survey (NHANES)

Considering the Framingham data as the source population, we use the NHANES data from 2017-2018 with the same covariates as the target population. We select variables including systolic blood pressure `BPXSY1`, gender `RIAGENDR`, age `RIDAGEYR`, Body Mass Index `BMXBMI`, cigarette smoking `SMQ040`/`SMQ020`, serum total cholesterol `LBXTC`, HDL cholesterol `LBXHDD`, diabetes `DIQ010`, and use of Anti-hypertensive medication `BPQ020`/`BPQ040A`/`BPQ050A`. The we followed the same step proceeded in the source population to add two variables about systolic blood pressure with medication treatment or not, and to filter ages ranging from 30 to 74. After exclusions, 3189 participants (mean age, 52 years; 1632 women) remained eligible. In Table 2, mean levels of serum total cholesterol and HDL cholesterol in the target population at the baseline examinations were significantly higher in women. In our middle-aged sample, the prevalences of diabetes and cigarettes smoking, as well as mean levels of systolic blood pressure, were substantially higher in men.

```{r}
# The NHANES data here finds the same covariates among this national survey data
library(nhanesA)

# blood pressure, demographic, bmi, smoking, and hypertension info
bpx_2017 <- nhanes("BPX_J") %>% 
  dplyr::select(SEQN, BPXSY1 ) %>% 
  rename(SYSBP = BPXSY1)
demo_2017 <- nhanes("DEMO_J") %>% 
  dplyr::select(SEQN, RIAGENDR, RIDAGEYR) %>% 
  rename(SEX = RIAGENDR, AGE = RIDAGEYR)
bmx_2017 <- nhanes("BMX_J") %>% 
  dplyr::select(SEQN, BMXBMI) %>% 
  rename(BMI = BMXBMI)
smq_2017 <- nhanes("SMQ_J") %>%
  mutate(CURSMOKE = case_when(SMQ040 %in% c(1,2) ~ 1,
                              SMQ040 == 3 ~ 0, 
                              SMQ020 == 2 ~ 0)) %>%
  dplyr::select(SEQN, CURSMOKE)
bpq_2017 <- nhanes("BPQ_J") %>% 
  mutate(BPMEDS = case_when(
    BPQ020 == 2 ~ 0,
    BPQ040A == 2 ~ 0,
    BPQ050A == 1 ~ 1,
    TRUE ~ NA )) %>%
  dplyr::select(SEQN, BPMEDS) 
tchol_2017 <- nhanes("TCHOL_J") %>% 
  dplyr::select(SEQN, LBXTC) %>% 
  rename(TOTCHOL = LBXTC)
hdl_2017 <- nhanes("HDL_J") %>% 
  dplyr::select(SEQN, LBDHDD) %>% 
  rename(HDLC = LBDHDD)
diq_2017 <- nhanes("DIQ_J") %>% 
  mutate(DIABETES = case_when(DIQ010 == 1 ~ 1, 
                              DIQ010 %in% c(2,3) ~ 0, 
                              TRUE ~ NA)) %>%
  dplyr::select(SEQN, DIABETES) 

# Join data from different tables
df_2017 <- bpx_2017 %>%
  full_join(demo_2017, by = "SEQN") %>%
  full_join(bmx_2017, by = "SEQN") %>%
  full_join(hdl_2017, by = "SEQN") %>%
  full_join(smq_2017, by = "SEQN") %>%
  full_join(bpq_2017, by = "SEQN") %>%
  full_join(tchol_2017, by = "SEQN") %>%
  full_join(diq_2017, by = "SEQN")

df_2017 <- df_2017 %>% 
  filter(AGE >= 30 & AGE <= 74) %>% 
  mutate(SYSBP_UT = ifelse(BPMEDS == 0, SYSBP, 0),
         SYSBP_T = ifelse(BPMEDS == 1, SYSBP, 0))

# factorize
df_2017$SEX <- as.factor(df_2017$SEX)
df_2017$CURSMOKE <- as.factor(df_2017$CURSMOKE)
df_2017$BPMEDS <- as.factor(df_2017$BPMEDS)
df_2017$DIABETES <- as.factor(df_2017$DIABETES)

df_2017 <- df_2017[!is.na(df_2017$SYSBP) & !is.na(df_2017$HDLC) & !is.na(df_2017$TOTCHOL) & !is.na(df_2017$BMI),]

df_2017 <- df_2017 %>% dplyr::select(-'SEQN')

#kable
kableone(CreateTableOne(data = df_2017, strata = c("SEX")), 
         caption = "Characteristics of Risk Factors Stratified by SEX in the NHANES Data",
         align = "c", booktabs = T,
         col.names = c("Men(1)", "Women(2)", "P-values", "")) %>%  
  kable_styling(full_width=T,latex_options = c('HOLD_position')) 
```

We exclude some participants with missingness in cholesterol-related variables, BMI, and blood pressures. After omitting those missing values, we have 6% of missingness in `BPMEDS` and only 1 record missing in `DIABETES`. Then we applied multiple imputation technique to infer those missing values with 5 imputation datasets. This method is trying to handle with each missing entry by estimating multiple reliable values such as regression models, running analysis across those completed dataset, aggregating all previous analyses results and analyzing how far they spread out in terms of standard deviations and confidence intervals.

# Transportability Analysis

We assume that outcome and covariate information is obtained from a simple random sample from the source population (the Framingham data, $S=1$). Furthermore, covariate information is obtained from a simple random sample from the target population (the NHANES data in 2017, $S = 0$), and no outcome information is collected from the target population. We assume the following identifiability conditions: (1) independence of the outcome and the population S conditioning on covariates $X$; (2) the probability of being from the source population conditioning on covariates must be greater than 0 for every $x$ with positive density in the target population. These tow fairly strong conditions will allow us to tailor the prediction model and assess its performance in the target population. Given 5 complete imputation datasets from the NHANES data and complete cases from the Framingham data, we will split each of them into training and test sets. To tailor the prediction model $g_{\hat{\beta}}(X)$ for use in the target population, we assume the model $g_{\beta}(X)$ is misspecified in most practical application cases. Then we estimate $\beta$ using the weighted maximum likelihood estimator, which can be obtain from the inverse of the odds of being from the source population. Although the inverse-odds weights are not identifiable, we assume, up to unknown proportionally constant, they are equal to the inverse-odds weights in the training set $\frac{Pr(S = 0)|X, D_{\text{train}} = 1}{Pr(S = 1)|X, D_{\text{train}} = 1}$[1].

```{r}
# check missingness percentage
# sapply(df_2017, function(x) sum(is.na(x))/nrow(df_2017))

# mice imputation
set.seed(1)
df_2017_mice_out <- mice(df_2017, m = 5, print = FALSE, seed = 2550)
df_2017_imp <- vector("list",5)    
for (i in 1:5){
  df_2017_imp[[i]] <- mice::complete(df_2017_mice_out,i)
}
```

```{r}
#make this example reproducible
set.seed(2550)

#use 80% of dataset as training set and 20% as test set
sample_framingham_men <- sample(c(TRUE, FALSE), nrow(framingham_df_men), replace=TRUE, prob=c(0.8,0.2))
framingham_df_men_train  <- framingham_df_men[sample_framingham_men, ]
framingham_df_men_test   <- framingham_df_men[!sample_framingham_men, ]


sample_framingham_women <- sample(c(TRUE, FALSE), nrow(framingham_df_women), replace=TRUE, prob=c(0.8,0.2))
framingham_df_women_train  <- framingham_df_women[sample_framingham_women, ]
framingham_df_women_test   <- framingham_df_women[!sample_framingham_women, ]

df_2017_imp_men <- vector("list", 5)
df_2017_imp_women <- vector("list", 5)
for (i in 1:5){
  df_2017_imp_men[[i]] <- df_2017_imp[[i]] %>% filter(SEX == 1) %>% mutate(S = 0)
  df_2017_imp_women[[i]] <- df_2017_imp[[i]] %>% filter(SEX == 2) %>% mutate(S = 0)
}

df_2017_imp_men_train <- vector("list", 5)
df_2017_imp_men_test <- vector("list", 5)
df_2017_imp_women_train <- vector("list", 5)
df_2017_imp_women_test <- vector("list", 5)
for (i in 1:5){
  sample_df_2017_men <- sample(c(TRUE, FALSE), nrow(df_2017_imp_men[[i]]), replace=TRUE, prob=c(0.8,0.2))
  sample_df_2017_women <- sample(c(TRUE, FALSE), nrow(df_2017_imp_women[[i]]), replace=TRUE, prob=c(0.8,0.2))
  df_2017_imp_men_train[[i]] <- df_2017_imp_men[[i]][sample_df_2017_men, ]
  df_2017_imp_men_test[[i]] <-  df_2017_imp_men[[i]][!sample_df_2017_men, ]
  df_2017_imp_women_train[[i]] <- df_2017_imp_women[[i]][sample_df_2017_women, ]
  df_2017_imp_women_test[[i]] <- df_2017_imp_women[[i]][!sample_df_2017_women, ]
}
```

Specifically, we will use 80% of the sex-specific Framingham dataset as training set and 20% as test set, as well as sex-specific imputation datasets. Following the above inverse-odds weights in the training dataset, we firstly combine training set from the Framingham and from each of training imputed 2017-NHANES sets under women and men categories separately, and then fit the logistic model with respect to the population $S$ given covariates mentioned above to get the inverse odds of being from the source population. Since this estimator for the inverse-odds weights is only applicable in the source population, we use the `predict()` function on the training Framingham dataset and take the inverse of exponentiation of predicted outcomes. We tailored the prediction model by adding weights in the `glm()` function with respect to `CVD` and refit the model again to obtain the new estimated $\beta$ coefficients. Given the tailored prediction model, we plugged into the Framingham test sets and set a threshold of 0.5 to cutoff the binary outcome 0 and 1. To get $\hat{\sigma}(X)$ of the inverse-odds weights in the test set $\frac{Pr(S = 0)|X, D_{\text{test}} = 1}{Pr(S = 1)|X, D_{\text{test}} = 1}$, we exponent results from the `predict()` function to the test Framingham data and calculate inverse. Given all those quantities, we estimate the Brier risk scores in the target population following the equation: $\hat{\phi}_{\beta} = \frac{\sum_{i=1}^{n} I(S_i = 1, D_{\text{test},i} = 1) \hat{\sigma}(X_i) (Y_i- g_{\hat{\beta}}(X_i))^2 }{\sum_{i=1}^{n} I(S_i= 0, D_{\text{test},i} = 1)}$.

```{r}
## Men
framingham_df_men_train <- framingham_df_men_train %>% mutate(S=1)
framingham_df_men_test <- framingham_df_men_test %>% mutate(S=1)
framingham_df_women_train <- framingham_df_women_train %>% mutate(S=1)
framingham_df_women_test <- framingham_df_women_test %>% mutate(S=1)

combined_train_men <- vector("list", 5)
combined_train_women <- vector("list", 5)

for (i in 1:5){
  combined_train_men[[i]] <- rbind(framingham_df_men_train[,-framingham_df_men_train$CVD], df_2017_imp_men_train[[i]])
  combined_train_women[[i]] <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[i]])
}

# combined_train_test <- rbind(framingham_df_men_test[,-framingham_df_men_test$CVD], df_2017_imp_men_test[[1]])

# weights 
logit_weights_men <- vector("list", 5)
inverse_weights_train_men <- vector("list", 5)
logit_outcome_train_men <- vector("list", 5)
g_X_men <- vector("list", 5)
pred_weights_men <- vector("list", 5)
inverse_weights_test_men <- vector("list", 5)
brier_score_df_men <- vector("list", 5)
brier_score_men <- vector("list", 5)

for (i in 1:5){
  logit_weights_men[[i]] <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_men[[i]], family= "binomial")
  inverse_weights_train_men[[i]] <- 1/(exp(predict(logit_weights_men[[i]], 
                                                   newdata = framingham_df_men_train)))
  logit_outcome_train_men[[i]] <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_men_train, 
               weights = inverse_weights_train_men[[i]], family= "binomial")
  # Brier Risk
  g_X_men[[i]] <- ifelse(predict(logit_outcome_train_men[[i]], 
                        newdata = framingham_df_men_test, type = "response") > 0.5, 1, 0)
  pred_weights_men[[i]] <- predict(logit_weights_men[[i]], newdata=framingham_df_men_test %>% dplyr::select(-'CVD'))
  inverse_weights_test_men[[i]] <- 1/(exp(pred_weights_men[[i]]))
  brier_score_df_men[[i]] <- data.frame(CVD = framingham_df_men_test$CVD, g_X = g_X_men[[i]], inverse_weights_test_men =inverse_weights_test_men[[i]]) 
  brier_score_df_men[[i]]$numerator <- (brier_score_df_men[[i]]$CVD
                                        -brier_score_df_men[[i]]$g_X)^2*brier_score_df_men[[i]]$inverse_weights_test_men
  brier_score_men[[i]] <- sum(brier_score_df_men[[i]]$numerator)/nrow(df_2017_imp_men_test[[i]])
}
brier_score_men_avg <- mean(unlist(brier_score_men))
```

```{r}
combined_train_women_1 <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[1]])
# weights 
logit_weights_1 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women_1, family= "binomial")

inverse_weights_train_1 <- 1/(exp(predict(logit_weights_1, newdata = framingham_df_women_train)))
# tailored model
logit_outcome_train_1 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = inverse_weights_train_1, family= "binomial")
# Brier Risk
g_X_1 <- ifelse(predict(logit_outcome_train_1, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_1 <- predict(logit_weights_1, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_1 <- 1/(exp(pred_weights_1))

brier_score_df_1 <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_1, inverse_weights_test =inverse_weights_test_1) 
brier_score_df_1$numerator <- (brier_score_df_1$CVD-brier_score_df_1$g_X)^2*inverse_weights_test_1
brier_score_1 <- sum(brier_score_df_1$numerator)/nrow(df_2017_imp_women_test[[1]])
```

```{r}
combined_train_women_2 <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[2]])
# weights 
logit_weights_2 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women_2, family= "binomial")

inverse_weights_train_2 <- 1/(exp(predict(logit_weights_2, newdata = framingham_df_women_train)))
# tailored model
logit_outcome_train_2 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = inverse_weights_train_2, family= "binomial")
# Brier Risk
g_X_2 <- ifelse(predict(logit_outcome_train_2, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_2 <- predict(logit_weights_2, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_2 <- 1/(exp(pred_weights_2))

brier_score_df_2 <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_2, inverse_weights_test =inverse_weights_test_2) 
brier_score_df_2$numerator <- (brier_score_df_2$CVD-brier_score_df_2$g_X)^2*inverse_weights_test_2
brier_score_2 <- sum(brier_score_df_2$numerator)/nrow(df_2017_imp_women_test[[2]])
```

```{r}
combined_train_women_3 <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[3]])
# weights 
logit_weights_3 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women_3, family= "binomial")

inverse_weights_train_3 <- 1/(exp(predict(logit_weights_3, newdata = framingham_df_women_train)))
# tailored model
logit_outcome_train_3 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = inverse_weights_train_3, family= "binomial")
# Brier Risk
g_X_3 <- ifelse(predict(logit_outcome_train_3, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_3 <- predict(logit_weights_3, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_3 <- 1/(exp(pred_weights_3))

brier_score_df_3 <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_3, inverse_weights_test =inverse_weights_test_3) 
brier_score_df_3$numerator <- (brier_score_df_3$CVD-brier_score_df_3$g_X)^2*inverse_weights_test_3
brier_score_3 <- sum(brier_score_df_3$numerator)/nrow(df_2017_imp_women_test[[3]])
```

```{r}
combined_train_women_4 <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[4]])
# weights 
logit_weights_4 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women_4, family= "binomial")

inverse_weights_train_4 <- 1/(exp(predict(logit_weights_4, newdata = framingham_df_women_train)))
# tailored model
logit_outcome_train_4 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = inverse_weights_train_4, family= "binomial")
# Brier Risk
g_X_4 <- ifelse(predict(logit_outcome_train_4, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_4 <- predict(logit_weights_4, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_4 <- 1/(exp(pred_weights_4))

brier_score_df_4 <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_4, inverse_weights_test =inverse_weights_test_4) 
brier_score_df_4$numerator <- (brier_score_df_4$CVD-brier_score_df_4$g_X)^2*inverse_weights_test_4
brier_score_4 <- sum(brier_score_df_4$numerator)/nrow(df_2017_imp_women_test[[4]])
```

```{r}
combined_train_women_5 <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], df_2017_imp_women_train[[5]])
# weights 
logit_weights_5 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women_5, family= "binomial")

inverse_weights_train_5 <- 1/(exp(predict(logit_weights_5, newdata = framingham_df_women_train)))
# tailored model
logit_outcome_train_5 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = inverse_weights_train_5, family= "binomial")
# Brier Risk
g_X_5 <- ifelse(predict(logit_outcome_train_5, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_5 <- predict(logit_weights_5, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_5 <- 1/(exp(pred_weights_5))

brier_score_df_5 <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_5, inverse_weights_test =inverse_weights_test_5) 
brier_score_df_5$numerator <- (brier_score_df_5$CVD-brier_score_df_5$g_X)^2*inverse_weights_test_5
brier_score_5 <- sum(brier_score_df_5$numerator)/nrow(df_2017_imp_women_test[[5]])
```

```{r}
brier_score_women <- mean(brier_score_1, brier_score_2, brier_score_3, brier_score_4, brier_score_5)
```

```{r, echo=FALSE, eval=FALSE}
# weights 
logit_weights_women <- vector("list", 5)
inverse_weights_train_women <- vector("list", 5)
logit_outcome_train_women <- vector("list", 5)
g_X_women <- vector("list", 5)
pred_weights_women <- vector("list", 5)
inverse_weights_test_women <- vector("list", 5)
brier_score_df_women <- vector("list", 5)
brier_score_women <- vector("list", 5)

for (i in 1:5){
  logit_weights_women[[i]] <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_train_women[[i]], family= "binomial")
  inverse_weights_train_women[[i]] <- 1/(exp(predict(logit_weights_women[[i]], 
                                                   newdata = framingham_df_women_train)))
  logit_outcome_train_women[[i]] <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, 
               weights = inverse_weights_train_women[[i]], family= "binomial")
  # Brier Risk
  g_X_women[[i]] <- ifelse(predict(logit_outcome_train_women[[i]], 
                        newdata = framingham_df_women_test, type = "response") > 0.5, 1, 0)
  pred_weights_women[[i]] <- predict(logit_weights_women[[i]], newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
  inverse_weights_test_women[[i]] <- 1/(exp(pred_weights_women[[i]]))
  brier_score_df_women[[i]] <- data.frame(CVD = framingham_df_women_test$CVD, g_X = g_X_women[[i]], inverse_weights_test_women = inverse_weights_test_women[[i]]) 
  brier_score_df_women[[i]]$numerator <- (brier_score_df_women[[i]]$CVD
                                        -brier_score_df_women[[i]]$g_X)^2*brier_score_df_women[[i]]$inverse_weights_test_women
  brier_score_df_women[[i]] <- sum(brier_score_df_women[[i]]$numerator)/nrow(df_2017_imp_women_test[[i]])
}
brier_score_women
mean(unlist(brier_score_women))
```

```{r}
brier_score_table <- data.frame(Men = c(brier_score_men[[1]], brier_score_men[[2]], brier_score_men[[3]], brier_score_men[[4]], brier_score_men[[5]], brier_score_men_avg), Women  = c(brier_score_1, brier_score_2, brier_score_3, brier_score_4, brier_score_5, brier_score_women))
rownames(brier_score_table) <- c("Composite Fram and Imp 1 Test", 
                                 "Composite Fram and Imp 2 Test", "Composite Fram and Imp 3 Test", "Composite Fram and Imp 4 Test", "Composite Fram and Imp 5 Test", "Average Estimation for Brier Risk")
colnames(brier_score_table) <- c("Men", "Women")
brier_score_table %>% round(3) %>% 
  kable(
        caption = "Estimated Brier Scores in the Target Population",
        align = "c",
        booktabs = T) %>% 
  kable_styling(full_width=T,latex_options = c('HOLD_position'))
```

Our results pertain to applications where the prediction model is built using the training data and is evaluated using the test data, and where the entire composite data set is split into a test and a training set that are used for model estimation and assessment[1]. Brier scores range between 0 and 1. A score of 0 represents perfect accuracy and a score of 1 represents perfect inaccuracy. Then, our results of Brier scores are closed to 0 by gender, which informed us a good performance of this tailored prediction model in this transportability analysis. 

# Illustration Using Simulated Data

Now we assume that individual level data is not available from the target population and only summary statistics with mean and standard deviation derived from the NHANES dataset are available. In the simulation study, we aim to investigate how estimation for the Brier score would be influenced in the simulated target population under different data generation processes for variables. The data generation method is varying in this section. In particular, we will focus on two ways. Firstly, we would like to get correlation insights from the source population (the Framingham study) by taking log transformation for each continuous variable. The second method is to determine the exact distribution followed by continuous variable in the Framingham data, and simulate it by 

The shared parameter is the number of samples to generate (N = 3000) and significance level of 0.05. As for the first data generation method, we took log transformation for each continuous variable to ensure the normality and tested the correlation matrix. Given fixed mean and standard deviation derived from the NHANES data, we simulated from a multivariate normal distribution with defined mean vector and covariance matrix of the continuous variables with the consideration of standard deviation. Except for continuous variable, we also considered about potential correlation between categorical variables, such as use of medication, and continuous variables, such as systolic blood pressure. To get the sense of association, we fitted the logistic model to determine if some variables are highly associated with binary outcomes. The first binary variable we examined is `BPMEDS`. The p-value showed that systolic blood pressure plays an important role in predicting the odds of use of medications, thus, we predicted `BPMEDS` in the simulated target population given the logistic regression model with respect to `BPMEDS` given important continuous predictors in the source population. We followed the same procedure to simulate gender variable. Specifically, given all simulated continuous variables and one categorical variable, we fitted the logistic regression model again in the Framingham data and examine the significance of predictors. Based on the results, we applied the `predict()` function on log transformation of simulated dataset and set a threshold of 0.5. By continually fitting logistic regression models with respect to categorical covariates in the source population, we get primary ideas about potential association between categorical and continuous variables and simulate the proportion of binary covariates by estimated coefficients of significant predictors. 

```{r}
set.seed(123)
# log continuous variable in framham
framingham_df$logAGE <- log(framingham_df$AGE)
framingham_df$logTOTCHOL <- log(framingham_df$TOTCHOL)
framingham_df$logSYSBP <- log(framingham_df$SYSBP)
framingham_df$logHDLC <- log(framingham_df$HDLC)
framingham_df$logBMI <- log(framingham_df$BMI)
log_contin_df <- data.frame(logTOTCHOL = log(framingham_df$TOTCHOL),
                            logHDLC = log(framingham_df$HDLC),
                            logBMI = log(framingham_df$BMI),
                            logSYSBP = log(framingham_df$SYSBP),
                            logAGE = log(framingham_df$AGE))
cor_mat_fram <- cor(log_contin_df)

# number of samples to generate
n_samples <- 3000

# mean and sd vectors 
means_cont <- c(192.66, 52.89, 30.32, 126.74, 52.41)
sd_cont <- c(41.26, 15.86, 7.33, 18.63, 12.60)

# generate random samples
simulate_data_1 <- mvrnorm(n_samples, mu = means_cont, Sigma = diag(sd_cont) %*% cor_mat_fram %*% diag(sd_cont))
# sd(as.data.frame(simulate_data_1)$V2)
simulate_data_1 <- as.data.frame(simulate_data_1)
colnames(simulate_data_1) <- c("TOTCHOL", "HDLC", "BMI", "SYSBP", "AGE")
simulate_data_log_1 <- log(simulate_data_1)
colnames(simulate_data_log_1) <- c("logTOTCHOL", "logHDLC", "logBMI", "logSYSBP", "logAGE")
```

```{r}
set.seed(123)
# cor.test(as.numeric(framingham_df$BPMEDS)-1, framingham_df$SYSBP)
# summary(glm(BPMEDS ~ logSYSBP+logBMI+logHDLC+logTOTCHOL+logAGE, data = framingham_df, family = "binomial"))
simulate_data_1$BPMEDS <- ifelse(predict(glm(BPMEDS ~ logSYSBP, data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_1)>0.5, 1,0)
simulate_data_log_1$BPMEDS <- simulate_data_1$BPMEDS
# table(simulate_data_1$BPMEDS)
# simulate_data_1$BPMEDS <- rbinom(n = 3000, size = 1, p = 0.32)
# simulate_data_log_1$BPMEDS <- simulate_data_1$BPMEDS
```

```{r}
# summary(glm(SEX ~ logSYSBP+logBMI+logHDLC+logTOTCHOL+logAGE+BPMEDS, data = framingham_df, family = "binomial"))
simulate_data_1$SEX <- ifelse(predict(glm(SEX ~ logBMI+logHDLC+logTOTCHOL+(as.numeric(BPMEDS)), data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_1)>0.5, 1,0)
simulate_data_1$SEX <- simulate_data_1$SEX+1
# table(simulate_data_1$SEX)
simulate_data_log_1$SEX <- simulate_data_1$SEX
```

```{r}
# glm(CURSMOKE ~ logBMI+logAGE+as.numeric(SEX), data = framingham_df, family = "binomial")
simulate_data_1$CURSMOKE <- ifelse(predict(glm(CURSMOKE ~ logBMI+logAGE+as.numeric(SEX), data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_1)>0.5, 1,0)
# table(simulate_data_1$CURSMOKE)
simulate_data_log_1$CURSMOKE <- simulate_data_1$CURSMOKE
```


```{r}
# summary(glm(DIABETES ~ logSYSBP+logBMI+logHDLC+logTOTCHOL+logAGE+BPMEDS+SEX+CURSMOKE, data = framingham_df, family = "binomial"))
simulate_data_1$DIABETES <- ifelse(predict(glm(DIABETES ~ logSYSBP+logAGE+logBMI, data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_1)>0.5, 1,0)
# table(simulate_data_1$CURSMOKE)
simulate_data_log_1$DIABETES <- simulate_data_1$DIABETES
```

```{r}
set.seed(123)
simulate_data_1 <- simulate_data_1 %>%  filter(AGE >= 30 & AGE <= 74) %>% 
  mutate(SYSBP_UT = ifelse(BPMEDS == 0, SYSBP, 0),
         SYSBP_T = ifelse(BPMEDS == 1, SYSBP, 0))

simulate_data_1_men <- simulate_data_1 %>% filter(SEX == 1) %>% mutate(S = 0)
simulate_data_1_women <- simulate_data_1 %>% filter(SEX == 2) %>% mutate(S = 0)

sample_simulate_data_1_men <- sample(c(TRUE, FALSE), nrow(simulate_data_1_men), replace=TRUE, prob=c(0.8,0.2))
sample_simulate_data_1_women <- sample(c(TRUE, FALSE), nrow(simulate_data_1_women), replace=TRUE, prob=c(0.8,0.2))
  
simulate_data_1_men_train <- simulate_data_1_men[sample_simulate_data_1_men, ]
simulate_data_1_men_test <-  simulate_data_1_men[!sample_simulate_data_1_men, ]
simulate_data_1_women_train <- simulate_data_1_women[sample_simulate_data_1_women, ]
simulate_data_1_women_test <- simulate_data_1_women[!sample_simulate_data_1_women, ]
```

```{r}
combined_simu_train_men <- rbind(framingham_df_men_train[,-framingham_df_men_train$CVD], simulate_data_1_men_train)
# weights 
simu_logit_weights_men <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_simu_train_men, family= "binomial")

simu_inverse_weights_train_men <- 1/(exp(predict(simu_logit_weights_men, newdata = framingham_df_men_train)))
# tailored model
simu_logit_outcome_train_men <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_men_train, weights = simu_inverse_weights_train_men, family= "binomial")
# Brier Risk
g_X_simu_men <- ifelse(predict(simu_logit_outcome_train_men, newdata = framingham_df_men_test, type = "response")>0.5, 1, 0)
pred_weights_simu_men <- predict(simu_logit_weights_men, newdata=framingham_df_men_test %>% dplyr::select(-'CVD'))
inverse_weights_test_simu_men <- 1/(exp(pred_weights_simu_men))
brier_score_simu_men <- sum((framingham_df_men_test$CVD-g_X_simu_men)^2*inverse_weights_test_simu_men)/nrow(simulate_data_1_men_test)
```

```{r}
combined_simu_train_women <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], simulate_data_1_women_train)
# weights 
simu_logit_weights_women <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_simu_train_women, family= "binomial")

simu_inverse_weights_train_women <- 1/(exp(predict(simu_logit_weights_women, newdata = framingham_df_women_train)))
# tailored model
simu_logit_outcome_train_women <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = simu_inverse_weights_train_women, family= "binomial")
# Brier Risk
g_X_simu_women <- ifelse(predict(simu_logit_outcome_train_women, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_simu_women <- predict(simu_logit_weights_women, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_simu_women <- 1/(exp(pred_weights_simu_women))
brier_simu_women <- sum((framingham_df_women_test$CVD-g_X_simu_women)^2*inverse_weights_test_simu_women)/nrow(simulate_data_1_women_test)
```

For the second data generation method, we particularly determined the distributions of continuous covariates in the source population, and simulated new individual-level data under certain parameters settings. We used `descdist()` function to compute descriptive parameters of an empirical distribution for non-censored data with bootstrapping method and provide a skewness-kurtosis plot. For example, the Cullen and Frey graph show us systolic blood pressure followed the gamma distribution in the source population, as the observation (blue) point is closed to the dashed line of theoretical gamma distribution. Then we used `fitdistr()` function to get the shape and rate parameters, and simulate the `SYSBP` under a gamma distribution with the shape parameter of 40.18 and the rate parameter of 0.29. Following the same step, we firstly determined theoretical distributions for each continuous variable based on Cullen and Frey graphs and used fixed mean and standard deviation values to simulate all continuous variables. In summary, `AGE` follows a normal distribution with mean of 52.41 and standard deviation of 12.60; systolic blood pressure `SYSBP` follows a gamma distribution with parameters mentioned above; `BMI` follows a log normal distribution with mean of 30.32 on the log scale and standard deviation of 7.33 on the log scale; `HDLC` follows a log normal distribution with mean of 52.89 on the log scale and standard deviation of 15.86 on the log scale; `TOTCHOL` follows a log normal distribution with mean of 192.66 on the log scale and standard deviation of 41.26 on the log scale. As for categorical variables, we follow the same procedure implemented in the first data generation method. Again, we fitted logistic regression models to understand association between specified categorical variables and other possible important covariates. The more variables we've simulated, the higher accuracy we can obtain for simulation of binary variables of interests. 
 
```{r, eval=FALSE}
## continuous variable in framingham
descdist(framingham_df$AGE, boot = 1000)
hist(framingham_df$AGE)
fit.norm.AGE <- fitdist(framingham_df$AGE, "norm")
fit.unif.AGE <- fitdist(framingham_df$AGE, "unif")
plot(fit.norm.AGE)
shapiro.test(framingham_df$AGE)
ks.test(framingham_df$AGE,"punif",30,74)
par(mfrow=c(2,2))
denscomp(list(fit.norm.AGE,fit.unif.AGE),legendtext=c("Normal","Uniform"))
qqcomp(list(fit.norm.AGE,fit.unif.AGE),legendtext=c("Normal","Uniform"))
cdfcomp(list(fit.norm.AGE,fit.unif.AGE),legendtext=c("Normal","Uniform"))
ppcomp(list(fit.norm.AGE,fit.unif.AGE),legendtext=c("Normal","Uniform"))
```

```{r,eval=FALSE}
descdist(framingham_df$SYSBP, boot = 1000)
fitdistr(framingham_df$SYSBP, "gamma")

descdist(framingham_df$BMI, boot = 1000, discrete = F)
fit.lnorm.BMI <- fitdist(framingham_df$BMI, "lnorm")
# plot(fit.lnorm.BMI)

descdist(framingham_df$HDLC, boot = 1000)
fit.lnorm.HDLC <- fitdist(framingham_df$HDLC, "lnorm")
plot(fit.lnorm.HDLC)

descdist(framingham_df$TOTCHOL, boot = 1000)
fit.lnorm.TOTCHOL <- fitdist(framingham_df$TOTCHOL, "lnorm")
plot(fit.lnorm.TOTCHOL)
```

```{r}
set.seed(1223)
# generate random samples
simulate_data_2 <- data.frame(SYSBP = rgamma(n = 3000, shape = 40.188129189, rate = 0.289561884),
                              BMI = rlnorm(n = 3000, meanlog = log(30.32), sdlog = log(7.33)),
                              HDLC = rlnorm(n = 3000, meanlog = log(52.89), sdlog = log(15.86)),
                              TOTCHOL = rlnorm(n = 3000, meanlog = log(192.66), sdlog = log(41.26)),
                              AGE = rnorm(n = 3000, mean = 52.41, sd = 12.60))
# simulate_data_2$logAGE <- log(simulate_data_2$AGE)
```


```{r}
simulate_data_log_2 <- data.frame(logSYSBP = log(simulate_data_2$SYSBP),
                              logBMI = simulate_data_2$BMI,
                              logHDLC = simulate_data_2$HDLC,
                              logTOTCHOL = simulate_data_2$TOTCHOL,
                              logAGE = log(simulate_data_2$AGE))
colnames(simulate_data_log_2) <- c("logSYSBP", "logBMI", "logHDLC", "logTOTCHOL", "logAGE")
```

```{r}
set.seed(123)
simulate_data_2$BPMEDS <- ifelse(predict(glm(BPMEDS ~ logSYSBP, data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_2)>0.5, 1,0)
simulate_data_log_2$BPMEDS <- simulate_data_2$BPMEDS
# table(simulate_data_2$BPMEDS)
# simulate_data_1$BPMEDS <- rbinom(n = 3000, size = 1, p = 0.32)
# simulate_data_log_1$BPMEDS <- simulate_data_1$BPMEDS
```

```{r}
simulate_data_2$SEX <- ifelse(predict(glm(SEX ~ logBMI+logHDLC+logTOTCHOL+(as.numeric(BPMEDS)), data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_2)>0.5, 1,0)
simulate_data_2$SEX <- simulate_data_2$SEX+1
# table(simulate_data_1$SEX)
simulate_data_log_2$SEX <- simulate_data_2$SEX
```

```{r}
# glm(CURSMOKE ~ logBMI+logAGE+as.numeric(SEX), data = framingham_df, family = "binomial")
simulate_data_2$CURSMOKE <- ifelse(predict(glm(CURSMOKE ~ logBMI+logAGE+as.numeric(SEX), data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_2)>0.5, 1,0)
# table(simulate_data_1$CURSMOKE)
simulate_data_log_2$CURSMOKE <- simulate_data_2$CURSMOKE
```


```{r}
# summary(glm(DIABETES ~ logSYSBP+logBMI+logHDLC+logTOTCHOL+logAGE+BPMEDS+SEX+CURSMOKE, data = framingham_df, family = "binomial"))
simulate_data_2$DIABETES <- ifelse(predict(glm(DIABETES ~ logSYSBP+logAGE+logBMI, data = framingham_df, family = "binomial"),type = "response", newdata = simulate_data_log_2)>0.5, 1,0)
# table(simulate_data_1$CURSMOKE)
simulate_data_log_2$DIABETES <- simulate_data_2$DIABETES
```

```{r}
set.seed(123)
simulate_data_2 <- simulate_data_2 %>%  filter(AGE >= 30 & AGE <= 74) %>% 
  mutate(SYSBP_UT = ifelse(BPMEDS == 0, SYSBP, 0),
         SYSBP_T = ifelse(BPMEDS == 1, SYSBP, 0))

simulate_data_2_men <- simulate_data_2 %>% filter(SEX == 1) %>% mutate(S = 0)
simulate_data_2_women <- simulate_data_2 %>% filter(SEX == 2) %>% mutate(S = 0)

sample_simulate_data_2_men <- sample(c(TRUE, FALSE), nrow(simulate_data_2_men), replace=TRUE, prob=c(0.8,0.2))
sample_simulate_data_2_women <- sample(c(TRUE, FALSE), nrow(simulate_data_2_women), replace=TRUE, prob=c(0.8,0.2))
  
simulate_data_2_men_train <- simulate_data_2_men[sample_simulate_data_2_men, ]
simulate_data_2_men_test <-  simulate_data_2_men[!sample_simulate_data_2_men, ]
simulate_data_2_women_train <- simulate_data_2_women[sample_simulate_data_2_women, ]
simulate_data_2_women_test <- simulate_data_2_women[!sample_simulate_data_2_women, ]
```

```{r}
combined_simu_train_men_2 <- rbind(framingham_df_men_train[,-framingham_df_men_train$CVD], simulate_data_2_men_train)
# weights 
simu_logit_weights_men_2 <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_simu_train_men_2, family= "binomial")

simu_inverse_weights_train_men_2 <- 1/(exp(predict(simu_logit_weights_men_2, newdata = framingham_df_men_train)))
# tailored model
simu_logit_outcome_train_men_2 <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_men_train, weights = simu_inverse_weights_train_men_2, family= "binomial")
# Brier Risk
g_X_simu_men_2 <- ifelse(predict(simu_logit_outcome_train_men_2, newdata = framingham_df_men_test, type = "response")>0.5, 1, 0)
pred_weights_simu_men_2 <- predict(simu_logit_weights_men_2, newdata=framingham_df_men_test %>% dplyr::select(-'CVD'))
inverse_weights_test_simu_men_2 <- 1/(exp(pred_weights_simu_men_2))
brier_score_simu_men_2 <- sum((framingham_df_men_test$CVD-g_X_simu_men_2)^2*inverse_weights_test_simu_men_2)/nrow(simulate_data_2_men_test)
```

```{r}
combined_simu_train_women <- rbind(framingham_df_women_train[,-framingham_df_women_train$CVD], simulate_data_2_women_train)
# weights 
simu_logit_weights_women <- glm(S ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                 log(SYSBP_T+1)+CURSMOKE+DIABETES, data= combined_simu_train_women, family= "binomial")

simu_inverse_weights_train_women <- 1/(exp(predict(simu_logit_weights_women, newdata = framingham_df_women_train)))
# tailored model
simu_logit_outcome_train_women <- glm(CVD ~ log(HDLC)+log(TOTCHOL)+log(AGE)+log(SYSBP_UT+1)+
                   log(SYSBP_T+1)+CURSMOKE+DIABETES, 
               data= framingham_df_women_train, weights = simu_inverse_weights_train_women, family= "binomial")
# Brier Risk
g_X_simu_women <- ifelse(predict(simu_logit_outcome_train_women, newdata = framingham_df_women_test, type = "response")>0.5, 1, 0)
pred_weights_simu_women <- predict(simu_logit_weights_women, newdata=framingham_df_women_test %>% dplyr::select(-'CVD'))
inverse_weights_test_simu_women <- 1/(exp(pred_weights_simu_women))
brier_simu_women <- sum((framingham_df_women_test$CVD-g_X_simu_women)^2*inverse_weights_test_simu_women)/nrow(simulate_data_2_women_test)
```


```{r}
simu_brier_score_table <- data.frame(Men = c(0.1749, 0.1346), Women  = c(0.0334, 0.0239))
rownames(simu_brier_score_table) <- c("Method 1", "Method 2")
colnames(simu_brier_score_table) <- c("Men", "Women")
simu_brier_score_table %>% round(4) %>% 
  kable(
        caption = "Estimated Brier Scores in the Simulated Target Population",
        align = "c",
        booktabs = T) %>% 
  kable_styling(full_width=T,latex_options = c('HOLD_position'))
```
In our simulation design, our focus is on estimating Brier risk scores based on proposed methods in published work. Then we, at the same time, utilize these scores by gender to evaluate tailored model performance in the simulated target population. The Table 4 consists of four Brier scores under each data generation method by sex. We can find that all Brier scores are less than estimations obtained from the 2017 NHANES data, which represents our simulation, to some extent, mimic the true distributions of covariates in the sample NHANES data. However, it is trivial to observe the second data generation method performs better in Brier scores by gender than the first one as we extract information about distribution exactly from the source population. As we simulated cases are truly closed to distribution in the source population so that we obtained with a lower Brier scores. 

# Limitations
The main limitation in our simulation study is the order of projection. For example, even though we found current smoking status and prevalence of diabetes play significant role in predicting participants' gender, due to the order of simulation process, we don't have information about cigarette smoking and diagnoses of diabetes prior to the simulation of gender, and are constrained to simulate correlated data at the current stage. Moreover, this simulation study doesn't account for other varying factors, such as number of simulations, number of samples to generate, and varying correlation matrices among covariates, which should be improved in the further studies. 

# Reference

1.  Steingrimsson, Jon A., et al. "Transporting a prediction model for use in a new target population." American Journal of Epidemiology 192.2 (2023): 296-304.

2.  Dâ€™Agostino Sr, Ralph B., et al. "General cardiovascular risk profile for use in primary care: the Framingham Heart Study." Circulation 117.6 (2008): 743-753.

3.  Li, Bing, et al. "Estimating the area under the ROC curve when transporting a prediction model to a target population." Biometrics 79.3 (2023): 2382-2393.

